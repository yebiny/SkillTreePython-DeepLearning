{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1rKzA_4xjd-n4MTl0eUawZrACOUcI--X3",
      "authorship_tag": "ABX9TyOZU5TgA73aDlA0we2JPvr+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yebiny/SkillTreePython-DeepLearning/blob/main/04.Paper-with-code/ch04_08_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ch04.08 Transformer\n",
        "\n",
        "* 날짜:\n",
        "* 이름:\n",
        "\n",
        "## 학습내용\n",
        "  - Transformer을 이해하고 구현한다.\n",
        "  - Vision Transformer을 이해하고 구현한다.\n",
        "\n",
        "## 참고 사이트\n",
        "\n",
        "   - 논문 [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf)\n"
      ],
      "metadata": {
        "id": "nLnUQASYQKZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhdd7a2LMGV5",
        "outputId": "703374d8-ff78-435a-a223-d43382cb461b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "sys.path.append('/content/drive/MyDrive/scripts/')\n",
        "from lib import *"
      ],
      "metadata": {
        "id": "FlxzeNvjD2dP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모듈 제작\n",
        "---"
      ],
      "metadata": {
        "id": "XcL9NVU8iYZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| Multi Head Attention**\n",
        "\n",
        "<p align='center'>\n",
        "<img src=https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/imgs/ch0408-09.PNG?raw=true?raw=true?raw=true\n",
        " width=350>\n",
        "</p>"
      ],
      "metadata": {
        "id": "xolCJasMbBLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* set params\n",
        "\n",
        "<p align='center'>\n",
        "<img src=https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/imgs/ch0408-01.PNG?raw=true?raw=true\n",
        " width=850>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "Pvbc9o05q-MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h = 8 \n",
        "d_k = 64\n",
        "d_v  = 64\n",
        "d_model = 64 * h #512  = embeding dims\n",
        "\n",
        "# 인풋 x shape \n",
        "# 시계열 : ( time range(window_size), channel )\n",
        "# 텍스트 : ( max lenth , vocab size )\n",
        "# 텍스트 임베딩 : (max lenth, embeding dims)\n",
        "\n",
        "# -> (V, K, Q)\n",
        "# T = S = max lenth\n",
        "# d_model = embedding dims\n",
        "T = 200\n",
        "S = 100\n",
        "\n",
        "Q = (T, d_model)\n",
        "K = (S, d_model)\n",
        "V = (S, d_model)\n",
        "print(Q)\n",
        "print(K)\n",
        "print(V)"
      ],
      "metadata": {
        "id": "GkyUk71jrBti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee0bfe64-4831-45bd-fb06-e77f899d3f54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 512)\n",
            "(100, 512)\n",
            "(100, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def matmul(shape1, shape2):\n",
        "  assert shape1[1]==shape2[0]\n",
        "  return (shape1[0], shape2[1])\n",
        "A = (100, 300)\n",
        "B = (300, 200)\n",
        "matmul(A, B)"
      ],
      "metadata": {
        "id": "qjGtR8OpwCUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7370817c-6da0-4b02-bccf-f28d23c7d21e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step1. Linear each  $Q, K, V(W^Q, W^K, W^V)$\n",
        "\n",
        "<br>\n",
        "\n",
        "<p align='center'>\n",
        "<img src=https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/imgs/ch0408-05.PNG?raw=true?raw=true?raw=true\n",
        " width=250>\n",
        "</p>\n",
        "\n",
        "<p align='center'>\n",
        "<img src=https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/imgs/ch0408-02-1.PNG?raw=true?raw=true\n",
        " width=850>\n",
        "</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "U2pu1Yk8rFay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set weights\n",
        "W_Q = (d_model, d_k)\n",
        "W_K = (d_model, d_k)\n",
        "W_V = (d_model, d_v) \n",
        "\n",
        "# calculate shape\n",
        "VW = matmul(V, W_V) \n",
        "KW = matmul(K, W_K) \n",
        "QW = matmul(Q, W_Q) \n",
        "\n",
        "print(f'Q {Q} x W_Q {W_Q} = {QW}')\n",
        "print(f'K {K} x W_K {W_K} = {KW}')\n",
        "print(f'V {V} x W_V {W_V} = {VW}')"
      ],
      "metadata": {
        "id": "-mgzUhEMwEAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd6b656-cae0-4711-edf5-b5270c49f8c4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q (200, 512) x W_Q (512, 64) = (200, 64)\n",
            "K (100, 512) x W_K (512, 64) = (100, 64)\n",
            "V (100, 512) x W_V (512, 64) = (100, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step2. Attention\n",
        "\n",
        "\n",
        "<p align='center'>\n",
        "<img src=https://wikidocs.net/images/page/159310/mha_img_original.png?raw=true\n",
        " width=450>\n",
        "</p>\n",
        "\n",
        "\n",
        "<p align='center'>\n",
        "<img src=https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/imgs/ch0408-03.PNG?raw=true?raw=true\n",
        " width=850>\n",
        "</p>"
      ],
      "metadata": {
        "id": "5Jt-3QHk5ceb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KW_T = (KW[1], KW[0])\n",
        "print(f\"QW: {QW}, KW_T: {KW_T}, VW: {VW}\")\n",
        "\n",
        "Att = matmul( matmul(QW, KW_T), VW )\n",
        "print(f'Attention(QW, KW, VW) : {Att}')"
      ],
      "metadata": {
        "id": "q4wy6SCaqcA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0824974-736a-4d86-ef59-e90e9d17fdeb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QW: (200, 64), KW_T: (64, 100), VW: (100, 64)\n",
            "Attention(QW, KW, VW) : (200, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* step3. concat & Linear $(W^O)$\n",
        "\n",
        "<p align='center'>\n",
        "<img src=https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/imgs/ch0408-10.PNG?raw=true?raw=true?raw=true\n",
        " width=300>\n",
        "</p>\n",
        "\n",
        "<p align='center'>\n",
        "<img src=https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/imgs/ch0408-04.PNG?raw=true?raw=true\n",
        " width=850>\n",
        "</p>"
      ],
      "metadata": {
        "id": "rpK9F02_61db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'- Attention(QW, KW, VW) = head {Att}')\n",
        "\n",
        "concat_att = (Att[0], Att[1]*h)\n",
        "print(f'- Concat(head_1, ...head_h) {concat_att}')\n",
        "\n",
        "W_O = ((h*d_v), d_model)\n",
        "final_out = matmul(concat_att, W_O)\n",
        "print(f'- Concat {concat_att} x W_O {W_O} = final output: {final_out}' )"
      ],
      "metadata": {
        "id": "ALvY3gFB5j2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bce1836-a421-4fac-e545-b99d14269b68"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Attention(QW, KW, VW) = head (200, 64)\n",
            "- Concat(head_1, ...head_h) (200, 512)\n",
            "- Concat (200, 512) x W_O (512, 512) = final output: (200, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('- 인풋: ',  V, K, Q)\n",
        "print(f'- 최종 아웃풋: {final_out}')"
      ],
      "metadata": {
        "id": "0yQlAMph8BQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a45674-313e-4d78-8d8a-150ba051cb6e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- 인풋:  (100, 512) (100, 512) (200, 512)\n",
            "- 최종 아웃풋: (200, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorflow.keras MultiHeadAttention Layer\n",
        "\n",
        "* docs: https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention\n",
        "\n",
        "```\n",
        "tf.keras.layers.MultiHeadAttention(\n",
        "    num_heads,\n",
        "    key_dim,\n",
        "    value_dim=None,\n",
        ")\n",
        "\n",
        "# call args\n",
        "\n",
        "query\tQuery Tensor of shape (B, T, dim).\n",
        "value\tValue Tensor of shape (B, S, dim).\n",
        "key\tOptional key Tensor of shape (B, S, dim). If not given, will use \n",
        "```"
      ],
      "metadata": {
        "id": "JlGlKBg57lRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h = 8 \n",
        "d_k = 64\n",
        "d_model = 64 * h #512  = embeding dims\n",
        "\n",
        "T = 200\n",
        "S = 100\n",
        "\n",
        "Q = layers.Input(shape=(T, d_model))\n",
        "V = layers.Input(shape=(S, d_model))\n",
        "\n",
        "y = layers.MultiHeadAttention(num_heads = h,\n",
        "                              key_dim = d_k,\n",
        "                              )(Q, V)\n",
        "                          "
      ],
      "metadata": {
        "id": "cOHRxGBxbE1C"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'- 인풋: V {V.shape} K {K.shape} Q {Q.shape}')\n",
        "print(f'- 최종 아웃풋: {y.shape}')"
      ],
      "metadata": {
        "id": "QRnjbqfvKmn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af5e3a3-88dd-4e28-f90c-0b18923e4ec6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- 인풋: V (None, 100, 512) K (None, 100, 512) Q (None, 200, 512)\n",
            "- 최종 아웃풋: (None, 200, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| Encoder Block**\n",
        "\n",
        "<p align='center'>\n",
        "<img src=https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/imgs/ch0408-11.PNG?raw=true?raw=true\n",
        " width=250>\n",
        "</p>"
      ],
      "metadata": {
        "id": "etBfO5Y9cHVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_block(Input_shape, h, d_k, d_ff, dropout=0.25, name=None):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Attention and Normalization\n",
        "    # multi-head\n",
        "    y = layers.MultiHeadAttention(num_heads= h,\n",
        "                                  key_dim= d_k, \n",
        "                                  dropout= dropout)(inputs, inputs)\n",
        "    y = layers.Dropout(dropout)(y)                        \n",
        "    # Add & Norm\n",
        "    y = layers.LayerNormalization(epsilon=1e-6)(y)\n",
        "    y_1 = layers.Add()([y, inputs])\n",
        "\n",
        "    # Feed Forward Part\n",
        "    # FF\n",
        "    y = layers.Conv1D(filters=d_ff, kernel_size=1, activation='relu')(y_1)\n",
        "    y = layers.Dropout(dropout)(y)\n",
        "    y = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1, activation='relu')(y)\n",
        "    # Add & Norm\n",
        "    y = layers.LayerNormalization(epsilon=1e-6)(y)\n",
        "    outputs = layers.Add()([y, y_1])\n",
        "\n",
        "    return models.Model(inputs, outputs, name=name)"
      ],
      "metadata": {
        "id": "e-hVfBKwMG9X"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (200, 128)\n",
        "h = 8\n",
        "d_k = 16\n",
        "d_ff = 32\n",
        "encoder = encoder_block(input_shape,\n",
        "                        h, \n",
        "                        d_k, \n",
        "                        d_ff)\n",
        "utils.plot_model(encoder, show_shapes=True)"
      ],
      "metadata": {
        "id": "ZRRQwBR6ayxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습1. 시계열 데이터 분류\n",
        "---"
      ],
      "metadata": {
        "id": "adsKf_GqrbFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 시계열 데이터셋**"
      ],
      "metadata": {
        "id": "tS8Z6BJxib6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y.astype(int)\n",
        "\n",
        "\n",
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
        "\n",
        "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
        "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "idx = np.random.permutation(len(x_train))\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]\n",
        "\n",
        "y_train[y_train == -1] = 0\n",
        "y_test[y_test == -1] = 0"
      ],
      "metadata": {
        "id": "1ngVAq1FEy1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, y_train.shape)\n"
      ],
      "metadata": {
        "id": "JrwNOqUXE3Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **| 모델 구현**"
      ],
      "metadata": {
        "id": "I-zZMs1xd2uI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set params\n",
        "\n",
        "\n",
        "# Set Input\n",
        "\n",
        "# Encoder Block\n",
        "\n",
        "\n",
        "# Classifier\n",
        "\n",
        "# Final model\n"
      ],
      "metadata": {
        "id": "1D4ITo01Z0HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hOpei2oVnJmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cwOBhu0XsBbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습2. IMDB 텍스트 분류\n",
        "---"
      ],
      "metadata": {
        "id": "6A9BPqyPrVo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| IMDB 데이터셋**\n"
      ],
      "metadata": {
        "id": "xnVcneSwigM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 20000  \n",
        "maxlen = 200  \n",
        "\n",
        "(x_train, y_train), (x_val, y_val) = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n",
        "print(len(x_train), \"Training sequences\")\n",
        "print(len(x_val), \"Validation sequences\")\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_val = tf.keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)\n",
        "print(x_train.shape, x_val.shape)"
      ],
      "metadata": {
        "id": "zanVdSOvfEMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "metadata": {
        "id": "S2LReh_CfiG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **| 모델 구현**"
      ],
      "metadata": {
        "id": "KZzxMCQDK5c7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set params\n",
        "\n",
        "\n",
        "# Set Input\n",
        "\n",
        "# Encoder Block\n",
        "\n",
        "\n",
        "# Classifier\n",
        "\n",
        "# Final model\n"
      ],
      "metadata": {
        "id": "RY3759qfK5c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 학습**"
      ],
      "metadata": {
        "id": "3bS4AnGMd65o"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mOCrC4IdW-if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_zuy7UIjmQOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uiqzzBnNXEg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습3. Vision Transformer\n",
        "---"
      ],
      "metadata": {
        "id": "Ga27rKRsuKgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_img_patches(img, patches):\n",
        "\n",
        "  # origin image\n",
        "\n",
        "\n",
        "  # patches\n",
        "\n",
        "  # real patches\n"
      ],
      "metadata": {
        "id": "jyvroA8DLeIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-BTU3lHQuMO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BW_l5s3_EnjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "njrj1EnTPfBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 이미지 증강**"
      ],
      "metadata": {
        "id": "ayGzpMWKLMgL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMdNJVrZPxyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| Patch 생성**"
      ],
      "metadata": {
        "id": "o7bXeAwN_mwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ApoNC3tUv0dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jWt00XZDv37Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| Patch Encoder**"
      ],
      "metadata": {
        "id": "NDDhrJtb_rKp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4TF3PvGB_kuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lf1Z-aaYBWUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **| 모델 구현**"
      ],
      "metadata": {
        "id": "9DnMP2RyLFmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set params\n",
        "\n",
        "\n",
        "# Set Input\n",
        "\n",
        "# Encoder Block\n",
        "\n",
        "\n",
        "# Classifier\n",
        "\n",
        "# Final model\n"
      ],
      "metadata": {
        "id": "mcmD_hQtLFmI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
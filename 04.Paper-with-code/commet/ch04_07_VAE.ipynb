{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/04.Paper-with-code/ch04_07_VAE.ipynb",
      "authorship_tag": "ABX9TyMGhMtjpqJVeQbVShcBlyUw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yebiny/SkillTreePython-DeepLearning/blob/main/04.Paper-with-code/commet/ch04_07_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ch04.07 Variational AutoEncoder\n",
        "\n",
        "* 날짜:\n",
        "* 이름:\n",
        "\n",
        "## 학습내용\n",
        "    - Variational AutoEncoder를 이해하고 구현한다.\n"
      ],
      "metadata": {
        "id": "nLnUQASYQKZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "sys.path.append('/content/drive/MyDrive/scripts/')\n",
        "from lib import *"
      ],
      "metadata": {
        "id": "EJIeT8-pWjEE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE 기본 구현\n",
        "---\n",
        "\n",
        "![](https://user-images.githubusercontent.com/24144491/50323466-18d03700-051d-11e9-82ed-afb1b6e2666a.png)"
      ],
      "metadata": {
        "id": "vFu4vTX1IeLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| Encoder, Decoder 구현**"
      ],
      "metadata": {
        "id": "pS1B1gq8Dds0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wa532XpF4y_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer): # 상속\n",
        "\n",
        "  def call(self, inputs):\n",
        "    z_mu, z_sigma = inputs\n",
        "    z_epsilon = tf.keras.backend.random_normal(shape=tf.shape(z_mu))\n",
        "    z = ( tf.exp(z_epsilon*0.5) * z_sigma ) + z_mu\n",
        "    return z\n",
        "\n",
        "class BuildModel():\n",
        "  def __init__(self, x_shape=(28,28,1), z_dims=100):\n",
        "    self.x_shape = x_shape\n",
        "    self.z_dims = z_dims\n",
        "\n",
        "  def build_encoder(self):\n",
        "    x = layers.Input(shape = self.x_shape )\n",
        "    z = layers.Conv2D(32, 3, strides=2, padding='same', activation='leaky_relu')(x)\n",
        "    z = layers.Conv2D(32, 3, strides=2, padding='same', activation='leaky_relu')(z)\n",
        "    self.z_conv_shape = z.shape[1:] # (7, 7, 32)\n",
        " \n",
        "    z = layers.Flatten()(z)\n",
        "    z_mu = layers.Dense(z_dims, activation='relu')(z)\n",
        "    z_sigma = layers.Dense(z_dims, activation='relu')(z)\n",
        "\n",
        "    z = Sampling()([z_mu, z_sigma])\n",
        "    encoder = models.Model(x, [z_mu, z_sigma, z], name='Encoder')\n",
        "    return encoder\n",
        "\n",
        "  def build_decoder(self):\n",
        "    z = layers.Input(shape = self.z_dims)\n",
        "    y = layers.Dense(256, activation='relu')(z)\n",
        "    dim = self.z_conv_shape[0]*self.z_conv_shape[1]*self.z_conv_shape[2]\n",
        "    y = layers.Dense(dim, activation = 'relu')(y)\n",
        "    y = layers.Reshape(self.z_conv_shape)(y)\n",
        "    y = layers.Conv2DTranspose(32, 3, strides=2, padding='same', activation='leaky_relu')(y)\n",
        "    y = layers.Conv2DTranspose(1, 3, strides=2, padding='same', activation='sigmoid')(y)\n",
        "\n",
        "    decoder = models.Model(z, y, name='Decoder')\n",
        "    return decoder"
      ],
      "metadata": {
        "id": "8bZEfX8knfdt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_shape = (28,28,1)\n",
        "z_dims = 10\n",
        "builder = BuildModel(x_shape, z_dims)\n",
        "encoder = builder.build_encoder()\n",
        "decoder = builder.build_decoder()\n",
        "encoder.summary()\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "WfRLfGfsddFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba4ff68-9296-4047-dd82-6c0a7afc1519"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_14 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 14, 14, 32)   320         ['input_14[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 7, 7, 32)     9248        ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_9 (Flatten)            (None, 1568)         0           ['conv2d_19[0][0]']              \n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 10)           15690       ['flatten_9[0][0]']              \n",
            "                                                                                                  \n",
            " dense_26 (Dense)               (None, 10)           15690       ['flatten_9[0][0]']              \n",
            "                                                                                                  \n",
            " sampling_9 (Sampling)          (None, 10)           0           ['dense_25[0][0]',               \n",
            "                                                                  'dense_26[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 40,948\n",
            "Trainable params: 40,948\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"Decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 10)]              0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 256)               2816      \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1568)              402976    \n",
            "                                                                 \n",
            " reshape_3 (Reshape)         (None, 7, 7, 32)          0         \n",
            "                                                                 \n",
            " conv2d_transpose_6 (Conv2DT  (None, 14, 14, 32)       9248      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_7 (Conv2DT  (None, 28, 28, 1)        289       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 415,329\n",
            "Trainable params: 415,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 손실함수 정의**\n",
        "\n",
        "![](https://user-images.githubusercontent.com/24144491/50323472-1a016400-051d-11e9-86b7-d8bf6a1a880f.png)"
      ],
      "metadata": {
        "id": "iiMmcIoWDiPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''loss.py'''\n",
        "def get_rec_loss(imgs, recs):\n",
        "  rec_loss = tf.keras.losses.binary_crossentropy(imgs, recs)\n",
        "  rec_loss = tf.reduce_mean(rec_loss)\n",
        "  return rec_loss\n",
        "\n",
        "def get_kl_loss(z_mu, z_sigma):\n",
        "  kl_loss = tf.square(z_mu) + ( -tf.exp(z_sigma) + z_sigma + 1)\n",
        "  kl_loss = -0.5*tf.reduce_mean(kl_loss)\n",
        "  return kl_loss"
      ],
      "metadata": {
        "id": "Cw_4DSPUhOWE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| VAE 구현**"
      ],
      "metadata": {
        "id": "BQtgvvbKlqil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE():\n",
        "  def __init__(self, encoder, decoder, x_shape):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.x_shape = x_shape\n",
        "\n",
        "  def compile(self, optimizer = tf.keras.optimizers.Adam() ):\n",
        "    img = layers.Input(shape = x_shape)\n",
        "    z_mu, z_sigma, z  = self.encoder(img)\n",
        "    rec = self.decoder(z)\n",
        "\n",
        "    self.vae = models.Model(img, rec, name='VAE')\n",
        "    self.optimizer = optimizer\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(self, imgs):\n",
        "    # imgs.shape = (16, 28, 28, 1)\n",
        "    with tf.GradientTape() as tape:\n",
        "      \n",
        "      # propagation\n",
        "      z_mu, z_sigma, z = self.encoder(imgs)\n",
        "      recs = self.decoder(z)\n",
        "\n",
        "      # loss 계산 - (rec loss / kl loss)\n",
        "      rec_loss = get_rec_loss(imgs, recs) # 원본 이미지와 재구성한 이미지가 최대한 비슷해지면 좋겠다\n",
        "      kl_loss = get_kl_loss(z_mu, z_sigma) # z가 다양하면서, 정보량 유사\n",
        "      loss = rec_loss + kl_loss\n",
        "\n",
        "    # gradient 계산\n",
        "    weights = self.vae.trainable_variables\n",
        "    gradients = tape.gradient(loss, weights)\n",
        "\n",
        "    # weight 업데이트\n",
        "    self.optimizer.apply_gradients(zip(gradients,weights))\n",
        "\n",
        "    return loss, rec_loss, kl_loss\n",
        "\n",
        "  def fit(self, x_data, epochs = 1, batch_size=16):\n",
        "\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices(x_data).batch(batch_size)\n",
        "    self.batch_size=batch_size\n",
        "    history = {'loss':[0 for i in range(epochs)], \n",
        "               'rec_loss':[0 for i in range(epochs)], \n",
        "               'kl_loss':[0 for i in range(epochs)] }\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "      self.epoch=epoch     \n",
        "      for imgs in train_ds:\n",
        "        loss, rec_loss, kl_loss = self.train_step(imgs)\n",
        "        history['loss'][epoch-1]+=loss\n",
        "        history['rec_loss'][epoch-1]+=rec_loss\n",
        "        history['kl_loss'][epoch-1]+=kl_loss\n",
        "      print(history)"
      ],
      "metadata": {
        "id": "R0sBydcaojKL"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dRaelPgaHM2U"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 학습**"
      ],
      "metadata": {
        "id": "PdNbThXwDT5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist():\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "  x_train = x_train.astype(np.float32) / 255\n",
        "  x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "  x_test = x_test.astype(np.float32) / 255\n",
        "  x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "  return x_train, x_test"
      ],
      "metadata": {
        "id": "VRZP2fnPjCLU"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test = get_mnist()\n",
        "x_train.shape, x_test.shape"
      ],
      "metadata": {
        "id": "VKyqpUj5jDYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf488af-43d4-4e51-d335-a985e39f36bf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (10000, 28, 28, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_shape = (28,28,1)\n",
        "z_dims = 100\n",
        "builder = BuildModel(x_shape, z_dims)\n",
        "encoder = builder.build_encoder()\n",
        "decoder = builder.build_decoder()\n",
        "\n",
        "vae = VAE(encoder, decoder, x_shape)\n",
        "vae.compile()\n",
        "vae.vae.summary()"
      ],
      "metadata": {
        "id": "tkwgCUhf7vJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e98d2f4-35f2-4aed-99ba-af8784c0e045"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"VAE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_27 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " Encoder (Functional)        [(None, 100),             323368    \n",
            "                              (None, 100),                       \n",
            "                              (None, 100)]                       \n",
            "                                                                 \n",
            " Decoder (Functional)        (None, 28, 28, 1)         438369    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 761,737\n",
            "Trainable params: 761,737\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DIxI81Q3J_j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.fit(x_train, 5)"
      ],
      "metadata": {
        "id": "KuZeBt-g6PMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 결과 확인**"
      ],
      "metadata": {
        "id": "mNxxpE5gPo5x"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BW_YtAFDGP3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7qXrdbsLGdjJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}